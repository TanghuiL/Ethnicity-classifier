{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity classifier with a Conv Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Joann H. Tang, Dr. Rahul Remanan\"\n",
    "__copyright__ = \"Copyright 2018\"\n",
    "__email__ = \"eagtang2007@gmail.com, rahul@remanan.net\"\n",
    "__status__ = \"Prototype\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "#Core layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#CNN layers\n",
    "from keras.layers import SeparableConv2D, Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Pooled/\"\n",
    "save_path = \"./model_weights.h5\"\n",
    "load_trained_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixel_values(prefix,y_label):\n",
    "    \"\"\"\n",
    "    Extract pixel values from images \n",
    "    \n",
    "    Arguments:\n",
    "    prefix -- The images for each class were labeled with a specific prefix\n",
    "    y_label -- The number assigned to represent a specific ethnicity group\n",
    "    Returns:\n",
    "    X -- pixel values of images, \n",
    "         numpy array of shape(number_of_images,250,250,3)\n",
    "    Y -- the ethnicity group label of images, \n",
    "         numpy array of shape(number_of_images)\n",
    "    \"\"\"\n",
    "    ims = glob.glob(path + prefix + \"*.jpg\")\n",
    "    Y = np.zeros((np.size(ims),1))\n",
    "    Y[:] = int(y_label)\n",
    "    X = np.zeros((np.size(ims),250,250,3)) #All images were resized to 250X250\n",
    "    for i, im in enumerate(ims):\n",
    "        img = Image.open(im)\n",
    "        X[i] = np.asarray(img)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X,Y,percentage):\n",
    "    \"\"\"\n",
    "    Shuffle and split the dataset into train and test subsets\n",
    "   \n",
    "    Arguments:\n",
    "    X -- numpy array of feature data, here, they are the pixel values of images\n",
    "    Y -- numpy array of label data\n",
    "    percentage -- the percentage of the total dataset that assigned as training set\n",
    "    \n",
    "    Returns:\n",
    "    x_train -- pixel values of images in the training set\n",
    "    y_train -- labels of images in the training set\n",
    "    x_val -- pixel values of images in the test set\n",
    "    y_val -- labels of images in the test set\n",
    "\n",
    "    \"\"\"\n",
    "    print (\"Group sample size: \" + str(np.size(Y)))\n",
    "    idx_train = np.random.randint(np.size(Y), size=round(np.size(Y)*percentage))\n",
    "    idx_val = np.random.randint(np.size(Y), size=round(np.size(Y)*(1-percentage)))\n",
    "    x_train = X[idx_train,:]\n",
    "    y_train = Y[idx_train]\n",
    "    x_val = X[idx_val,:]\n",
    "    y_val = Y[idx_val]\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating dataset\n",
    "\n",
    "This project uses the [United States Census Bureau classification of ethinicites in the US](https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States).\n",
    "\n",
    "#### Currently the dataset is limited to four ethnic groups in the US:\n",
    "\n",
    "1) Asian American\n",
    "\n",
    "2) Black and African American\n",
    "\n",
    "3) Caucasian/White and Euroopean American\n",
    "\n",
    "4) Hispanic and Latino American\n",
    "\n",
    "#### The dataset is missing information on:\n",
    "\n",
    "1) Native American and Alaska Native\n",
    "\n",
    "2) Native Hawaiian and other Pacific Islander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity group -- Asian American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = extract_pixel_values(\"A\",0)                          \n",
    "x1_train,y1_train,x1_val,y1_val = split_dataset(X,Y,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity group -- Black and African American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = extract_pixel_values(\"B\",1)                          \n",
    "x2_train,y2_train,x2_val,y2_val = split_dataset(X,Y,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity group -- Caucasian/White and European American "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = extract_pixel_values(\"C\",2)                          \n",
    "x3_train,y3_train,x3_val,y3_val = split_dataset(X,Y,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity group -- Hispanic and Latino Americans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = extract_pixel_values(\"H\",3)                          \n",
    "x4_train,y4_train,x4_val,y4_val = split_dataset(X,Y,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x1_train, x2_train, x3_train, x4_train), axis=0)\n",
    "y_train = np.concatenate((y1_train, y2_train, y3_train, y4_train), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.concatenate((x1_val, x2_val, x3_val, x4_val), axis=0)\n",
    "y_val = np.concatenate((y1_val, y2_val, y3_val, y4_val), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train, y_train, random_state=1024)\n",
    "x_val, y_val = shuffle(x_val, y_val, random_state=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring data casting to the right data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train).astype('float32')\n",
    "x_val = (x_val).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_val /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up  parameters for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 4\n",
    "epochs = 5\n",
    "dropout = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(np.asarray(y_train), num_classes)\n",
    "y_val = keras.utils.to_categorical(np.asarray(y_val), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare a sequential model\n",
    "model = Sequential()\n",
    "#CNN input layer \n",
    "model.add(SeparableConv2D(32, kernel_size =(3,3), \n",
    "                 activation='relu', \n",
    "                 depth_multiplier = 3,\n",
    "                 padding = 'same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "#Add hidden layers to the model \n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "#Fully connected Dense layers \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "import io, json\n",
    "with io.open('model.config', 'w', encoding='utf-8') as f:\n",
    "  f.write(json.dumps(model_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_trained_model:\n",
    "    model.load_weights(save_path, by_name = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation on the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018 update 2)",
   "language": "python",
   "name": "intel_distribution_of_python_3_2018u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
