{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity classifier with a Conv Net\n",
    "A classifier to identify the ethnicity of a person's face. The core of the classifier machine is a Convolutional Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Joann H. Tang, PhD\"\n",
    "__copyright__ = \"Copyright 2018\"\n",
    "__email__ = \"eagtang2007@gmail.com\"\n",
    "__status__ = \"Prototype\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "#Core layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#CNN layers\n",
    "from keras.layers import SeparableConv2D, Conv2D, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import io,json\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.utils import shuffle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/huizhentang/Documents/Repos/Pet-projects/Ethnicity-Classifier/Datasets/\"\n",
    "save_path = \"/Users/huizhentang/Documents/Repos/Pet-projects/Ethnicity-Classifier/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up parameters for the classifier¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "num_classes = 4\n",
    "epochs = 100\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the database. \n",
    "conn = sqlite3.connect(path + 'ethface.db')\n",
    "cur = conn.cursor() \n",
    "\n",
    "#Load data from databse using pandas.read_sql_query. \n",
    "x = pd.read_sql_query(\"SELECT * FROM ethface_asian_features;\", conn)\n",
    "y = pd.read_sql_query(\"SELECT * FROM ethface_asian_labels;\", conn)\n",
    "\n",
    "#Close connection to database\n",
    "cur.close() \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop('index', axis=1, inplace=True)\n",
    "y.drop('index', axis=1, inplace=True)\n",
    "x = x.values #Convert dataframe to array\n",
    "n = int(len(x[:,0])/(128*128))\n",
    "x = np.reshape(x,(n,128,128,3), order='C')\n",
    "y = y.values #Convert dataframe to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data formatting and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring data casting to the right data type\n",
    "x = (x).astype('float32')\n",
    "#Feature normalization\n",
    "x /= 255\n",
    "#Convert class vectors to binary class matrices¶\n",
    "y = keras.utils.to_categorical(np.asarray(y), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset into training, validation, and test set¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X,Y,p_train,p_val,p_test):\n",
    "    \"\"\"\n",
    "    Randomly select a defined percentge of the dataset as train set \n",
    "    and divide the rest for validation set and test set \n",
    "   \n",
    "    Arguments:\n",
    "    X -- numpy array of feature data, here, they are the pixel values of images\n",
    "    Y -- numpy array of label data\n",
    "    p_train -- the percentage of the total dataset that assigned as training set\n",
    "    p_train -- the percentage of the total dataset that assigned as validation set\n",
    "    p_train -- the percentage of the total dataset that assigned as testing set\n",
    "    \n",
    "    Returns:\n",
    "    x_train -- pixel values of images in the training set\n",
    "    y_train -- labels of images in the training set\n",
    "    x_val -- pixel values of images in the validation set\n",
    "    y_val -- labels of images in the validation set\n",
    "    x_test -- pixel values of images in the test set\n",
    "    y_test -- labels of images in the test set\n",
    "\n",
    "    \"\"\"\n",
    "    X, Y = shuffle(X, Y, random_state=42) \n",
    "    n_train = round(len(Y[:,0])*p_train)\n",
    "    n_val = round(len(Y[:,0])*p_val)\n",
    "    n_test = round(len(Y[:,0])*p_test)\n",
    "    idx_train = list(range(0,n_train))\n",
    "    idx_val = list(range(n_train,n_train+n_val))\n",
    "    idx_test = list(range(n_train+n_val,len(Y[:,0])))\n",
    "    x_train = X[idx_train,:]\n",
    "    y_train = Y[idx_train,:]\n",
    "    x_val = X[idx_val,:]\n",
    "    y_val = Y[idx_val,:]\n",
    "    x_test = X[idx_test,:]\n",
    "    y_test = Y[idx_test,:]\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2696, 128, 128, 3)\n",
      "(2696, 4)\n",
      "(1348, 128, 128, 3)\n",
      "(1348, 4)\n",
      "(449, 128, 128, 3)\n",
      "(449, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_val,y_val,x_test,y_test=split_dataset(x,y,0.6,0.3,0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare a sequential model\n",
    "model = Sequential()\n",
    "#CNN input layer \n",
    "model.add(SeparableConv2D(32, kernel_size =(3,3), \n",
    "                 activation='relu', \n",
    "                 depth_multiplier = 3,\n",
    "                 padding = 'same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "\n",
    "#Add hidden layers to the model \n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "#Fully connected Dense layers \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_1 (Separabl (None, 128, 128, 32)      401       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 6,490,165\n",
      "Trainable params: 6,490,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2696 samples, validate on 1348 samples\n",
      "Epoch 1/100\n",
      "2696/2696 [==============================] - 140s 52ms/step - loss: 1.4577 - acc: 0.2749 - val_loss: 1.3833 - val_acc: 0.2967\n",
      "Epoch 2/100\n",
      "2696/2696 [==============================] - 142s 53ms/step - loss: 1.3810 - acc: 0.2986 - val_loss: 1.3744 - val_acc: 0.2967\n",
      "Epoch 3/100\n",
      "2696/2696 [==============================] - 142s 53ms/step - loss: 1.3615 - acc: 0.3190 - val_loss: 1.3409 - val_acc: 0.3472\n",
      "Epoch 4/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 1.3125 - acc: 0.3809 - val_loss: 1.3290 - val_acc: 0.3650\n",
      "Epoch 5/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 1.2640 - acc: 0.4310 - val_loss: 1.3214 - val_acc: 0.3642\n",
      "Epoch 6/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 1.1773 - acc: 0.4822 - val_loss: 1.2902 - val_acc: 0.4028\n",
      "Epoch 7/100\n",
      "2696/2696 [==============================] - 144s 54ms/step - loss: 1.0646 - acc: 0.5453 - val_loss: 1.3609 - val_acc: 0.4258\n",
      "Epoch 8/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 0.9194 - acc: 0.6168 - val_loss: 1.4583 - val_acc: 0.4266\n",
      "Epoch 9/100\n",
      "2696/2696 [==============================] - 148s 55ms/step - loss: 0.7205 - acc: 0.7203 - val_loss: 1.7088 - val_acc: 0.4228\n",
      "Epoch 10/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.5879 - acc: 0.7841 - val_loss: 1.7971 - val_acc: 0.4436\n",
      "Epoch 11/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 0.4548 - acc: 0.8372 - val_loss: 2.0258 - val_acc: 0.4280\n",
      "Epoch 12/100\n",
      "2696/2696 [==============================] - 141s 52ms/step - loss: 0.3899 - acc: 0.8702 - val_loss: 2.2493 - val_acc: 0.4377\n",
      "Epoch 13/100\n",
      "2696/2696 [==============================] - 141s 52ms/step - loss: 0.2877 - acc: 0.9080 - val_loss: 2.5415 - val_acc: 0.4117\n",
      "Epoch 14/100\n",
      "2696/2696 [==============================] - 141s 52ms/step - loss: 0.2520 - acc: 0.9262 - val_loss: 2.5502 - val_acc: 0.3999\n",
      "Epoch 15/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.2259 - acc: 0.9325 - val_loss: 2.4195 - val_acc: 0.4073\n",
      "Epoch 16/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 0.1972 - acc: 0.9418 - val_loss: 2.3122 - val_acc: 0.4206\n",
      "Epoch 17/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1687 - acc: 0.9470 - val_loss: 2.6522 - val_acc: 0.4258\n",
      "Epoch 18/100\n",
      "2696/2696 [==============================] - 147s 55ms/step - loss: 0.1813 - acc: 0.9488 - val_loss: 2.4312 - val_acc: 0.4199\n",
      "Epoch 19/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1652 - acc: 0.9510 - val_loss: 2.7158 - val_acc: 0.4050\n",
      "Epoch 20/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1429 - acc: 0.9518 - val_loss: 2.5701 - val_acc: 0.4080\n",
      "Epoch 21/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1478 - acc: 0.9529 - val_loss: 2.4977 - val_acc: 0.4206\n",
      "Epoch 22/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1230 - acc: 0.9596 - val_loss: 2.4634 - val_acc: 0.4199\n",
      "Epoch 23/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.1341 - acc: 0.9573 - val_loss: 2.5531 - val_acc: 0.4147\n",
      "Epoch 24/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1171 - acc: 0.9577 - val_loss: 2.6582 - val_acc: 0.4006\n",
      "Epoch 25/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.1180 - acc: 0.9614 - val_loss: 2.4715 - val_acc: 0.4191\n",
      "Epoch 26/100\n",
      "2696/2696 [==============================] - 147s 54ms/step - loss: 0.1145 - acc: 0.9607 - val_loss: 2.5401 - val_acc: 0.4206\n",
      "Epoch 27/100\n",
      "2696/2696 [==============================] - 147s 55ms/step - loss: 0.1204 - acc: 0.9570 - val_loss: 2.6633 - val_acc: 0.4065\n",
      "Epoch 28/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1176 - acc: 0.9566 - val_loss: 2.5394 - val_acc: 0.4125\n",
      "Epoch 29/100\n",
      "2696/2696 [==============================] - 148s 55ms/step - loss: 0.1158 - acc: 0.9607 - val_loss: 2.5293 - val_acc: 0.4199\n",
      "Epoch 30/100\n",
      "2696/2696 [==============================] - 142s 53ms/step - loss: 0.0941 - acc: 0.9625 - val_loss: 2.7396 - val_acc: 0.4154\n",
      "Epoch 31/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.1058 - acc: 0.9618 - val_loss: 2.6336 - val_acc: 0.4273\n",
      "Epoch 32/100\n",
      "2696/2696 [==============================] - 144s 54ms/step - loss: 0.1058 - acc: 0.9585 - val_loss: 2.8095 - val_acc: 0.4228\n",
      "Epoch 33/100\n",
      "2696/2696 [==============================] - 148s 55ms/step - loss: 0.0999 - acc: 0.9585 - val_loss: 2.5504 - val_acc: 0.4236\n",
      "Epoch 34/100\n",
      "2696/2696 [==============================] - 149s 55ms/step - loss: 0.0946 - acc: 0.9633 - val_loss: 2.7342 - val_acc: 0.4236\n",
      "Epoch 35/100\n",
      "2696/2696 [==============================] - 149s 55ms/step - loss: 0.0871 - acc: 0.9636 - val_loss: 2.6797 - val_acc: 0.4162\n",
      "Epoch 36/100\n",
      "2696/2696 [==============================] - 147s 54ms/step - loss: 0.0931 - acc: 0.9592 - val_loss: 2.5914 - val_acc: 0.3991\n",
      "Epoch 37/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0929 - acc: 0.9607 - val_loss: 2.6190 - val_acc: 0.4251\n",
      "Epoch 38/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0983 - acc: 0.9585 - val_loss: 2.7597 - val_acc: 0.4050\n",
      "Epoch 39/100\n",
      "2696/2696 [==============================] - 144s 54ms/step - loss: 0.0873 - acc: 0.9636 - val_loss: 2.6665 - val_acc: 0.4228\n",
      "Epoch 40/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.0833 - acc: 0.9662 - val_loss: 2.7108 - val_acc: 0.4310\n",
      "Epoch 41/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0890 - acc: 0.9607 - val_loss: 2.7563 - val_acc: 0.4132\n",
      "Epoch 42/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.0909 - acc: 0.9611 - val_loss: 2.7010 - val_acc: 0.4273\n",
      "Epoch 43/100\n",
      "2696/2696 [==============================] - 148s 55ms/step - loss: 0.0818 - acc: 0.9618 - val_loss: 2.7652 - val_acc: 0.4065\n",
      "Epoch 44/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0825 - acc: 0.9633 - val_loss: 2.8012 - val_acc: 0.4177\n",
      "Epoch 45/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0785 - acc: 0.9659 - val_loss: 2.7312 - val_acc: 0.4295\n",
      "Epoch 46/100\n",
      "2696/2696 [==============================] - 141s 52ms/step - loss: 0.0923 - acc: 0.9577 - val_loss: 2.7487 - val_acc: 0.3961\n",
      "Epoch 47/100\n",
      "2696/2696 [==============================] - 145s 54ms/step - loss: 0.0871 - acc: 0.9618 - val_loss: 3.0664 - val_acc: 0.4021\n",
      "Epoch 48/100\n",
      "2696/2696 [==============================] - 154s 57ms/step - loss: 0.0952 - acc: 0.9599 - val_loss: 2.7427 - val_acc: 0.4102\n",
      "Epoch 49/100\n",
      "2696/2696 [==============================] - 161s 60ms/step - loss: 0.0850 - acc: 0.9659 - val_loss: 2.5903 - val_acc: 0.4243\n",
      "Epoch 50/100\n",
      "2696/2696 [==============================] - 158s 59ms/step - loss: 0.0760 - acc: 0.9629 - val_loss: 2.7092 - val_acc: 0.4050\n",
      "Epoch 51/100\n",
      "2696/2696 [==============================] - 153s 57ms/step - loss: 0.0775 - acc: 0.9651 - val_loss: 2.6960 - val_acc: 0.3909\n",
      "Epoch 52/100\n",
      "2696/2696 [==============================] - 157s 58ms/step - loss: 0.0706 - acc: 0.9659 - val_loss: 2.8448 - val_acc: 0.4332\n",
      "Epoch 53/100\n",
      "2696/2696 [==============================] - 153s 57ms/step - loss: 0.0820 - acc: 0.9588 - val_loss: 2.7824 - val_acc: 0.3991\n",
      "Epoch 54/100\n",
      "2696/2696 [==============================] - 155s 58ms/step - loss: 0.0694 - acc: 0.9662 - val_loss: 2.7797 - val_acc: 0.4362\n",
      "Epoch 55/100\n",
      "2696/2696 [==============================] - 162s 60ms/step - loss: 0.0784 - acc: 0.9633 - val_loss: 2.8474 - val_acc: 0.4347\n",
      "Epoch 56/100\n",
      "2696/2696 [==============================] - 152s 56ms/step - loss: 0.0790 - acc: 0.9633 - val_loss: 2.6034 - val_acc: 0.4236\n",
      "Epoch 57/100\n",
      "2696/2696 [==============================] - 143s 53ms/step - loss: 0.0733 - acc: 0.9611 - val_loss: 2.8929 - val_acc: 0.4043\n",
      "Epoch 58/100\n",
      "2696/2696 [==============================] - 156s 58ms/step - loss: 0.0773 - acc: 0.9640 - val_loss: 2.7228 - val_acc: 0.4325\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2696/2696 [==============================] - 152s 56ms/step - loss: 0.0758 - acc: 0.9622 - val_loss: 2.7518 - val_acc: 0.4280\n",
      "Epoch 60/100\n",
      "2696/2696 [==============================] - 151s 56ms/step - loss: 0.0709 - acc: 0.9674 - val_loss: 2.8806 - val_acc: 0.4095\n",
      "Epoch 61/100\n",
      "2696/2696 [==============================] - 152s 56ms/step - loss: 0.0711 - acc: 0.9633 - val_loss: 2.8850 - val_acc: 0.4102\n",
      "Epoch 62/100\n",
      "2696/2696 [==============================] - 152s 56ms/step - loss: 0.0691 - acc: 0.9625 - val_loss: 2.8834 - val_acc: 0.4154\n",
      "Epoch 63/100\n",
      "2696/2696 [==============================] - 152s 57ms/step - loss: 0.0711 - acc: 0.9636 - val_loss: 3.0224 - val_acc: 0.4295\n",
      "Epoch 64/100\n",
      "2696/2696 [==============================] - 149s 55ms/step - loss: 0.0833 - acc: 0.9607 - val_loss: 2.7403 - val_acc: 0.4191\n",
      "Epoch 65/100\n",
      "2696/2696 [==============================] - 139s 52ms/step - loss: 0.0766 - acc: 0.9648 - val_loss: 2.8528 - val_acc: 0.4295\n",
      "Epoch 66/100\n",
      "2696/2696 [==============================] - 164s 61ms/step - loss: 0.0709 - acc: 0.9648 - val_loss: 2.7993 - val_acc: 0.4303\n",
      "Epoch 67/100\n",
      "2696/2696 [==============================] - 159s 59ms/step - loss: 0.0683 - acc: 0.9640 - val_loss: 2.8288 - val_acc: 0.4206\n",
      "Epoch 68/100\n",
      "2696/2696 [==============================] - 167s 62ms/step - loss: 0.0690 - acc: 0.9633 - val_loss: 2.9653 - val_acc: 0.3917\n",
      "Epoch 69/100\n",
      "2696/2696 [==============================] - 169s 63ms/step - loss: 0.0795 - acc: 0.9596 - val_loss: 3.1804 - val_acc: 0.3791\n",
      "Epoch 70/100\n",
      "2696/2696 [==============================] - 175s 65ms/step - loss: 0.0852 - acc: 0.9622 - val_loss: 3.0606 - val_acc: 0.4132\n",
      "Epoch 71/100\n",
      "2696/2696 [==============================] - 172s 64ms/step - loss: 0.0790 - acc: 0.9622 - val_loss: 2.9063 - val_acc: 0.4102\n",
      "Epoch 72/100\n",
      "2696/2696 [==============================] - 167s 62ms/step - loss: 0.0637 - acc: 0.9644 - val_loss: 2.9368 - val_acc: 0.4206\n",
      "Epoch 73/100\n",
      "2696/2696 [==============================] - 164s 61ms/step - loss: 0.0723 - acc: 0.9655 - val_loss: 2.9444 - val_acc: 0.4065\n",
      "Epoch 74/100\n",
      "2696/2696 [==============================] - 157s 58ms/step - loss: 0.0711 - acc: 0.9644 - val_loss: 2.8561 - val_acc: 0.3991\n",
      "Epoch 75/100\n",
      "2696/2696 [==============================] - 153s 57ms/step - loss: 0.0713 - acc: 0.9651 - val_loss: 2.7136 - val_acc: 0.4162\n",
      "Epoch 76/100\n",
      "2696/2696 [==============================] - 140s 52ms/step - loss: 0.0677 - acc: 0.9655 - val_loss: 2.8469 - val_acc: 0.4258\n",
      "Epoch 77/100\n",
      "2696/2696 [==============================] - 144s 53ms/step - loss: 0.0637 - acc: 0.9681 - val_loss: 2.9037 - val_acc: 0.4110\n",
      "Epoch 78/100\n",
      "2696/2696 [==============================] - 141s 52ms/step - loss: 0.0630 - acc: 0.9640 - val_loss: 2.8488 - val_acc: 0.4228\n",
      "Epoch 79/100\n",
      "2696/2696 [==============================] - 141s 52ms/step - loss: 0.0645 - acc: 0.9625 - val_loss: 2.7578 - val_acc: 0.4273\n",
      "Epoch 80/100\n",
      "2696/2696 [==============================] - 148s 55ms/step - loss: 0.0637 - acc: 0.9655 - val_loss: 2.9142 - val_acc: 0.4058\n",
      "Epoch 81/100\n",
      "2696/2696 [==============================] - 149s 55ms/step - loss: 0.0847 - acc: 0.9611 - val_loss: 3.0756 - val_acc: 0.4110\n",
      "Epoch 82/100\n",
      "2696/2696 [==============================] - 147s 55ms/step - loss: 0.0782 - acc: 0.9607 - val_loss: 3.1186 - val_acc: 0.4154\n",
      "Epoch 83/100\n",
      "2696/2696 [==============================] - 149s 55ms/step - loss: 0.0739 - acc: 0.9633 - val_loss: 3.1290 - val_acc: 0.3843\n",
      "Epoch 84/100\n",
      "2696/2696 [==============================] - 149s 55ms/step - loss: 0.0791 - acc: 0.9633 - val_loss: 3.0435 - val_acc: 0.4073\n",
      "Epoch 85/100\n",
      "2696/2696 [==============================] - 151s 56ms/step - loss: 0.0700 - acc: 0.9648 - val_loss: 3.1960 - val_acc: 0.4043\n",
      "Epoch 86/100\n",
      "2696/2696 [==============================] - 152s 56ms/step - loss: 0.0716 - acc: 0.9607 - val_loss: 3.0327 - val_acc: 0.4139\n",
      "Epoch 87/100\n",
      "2696/2696 [==============================] - 186s 69ms/step - loss: 0.0623 - acc: 0.9651 - val_loss: 2.7728 - val_acc: 0.4228\n",
      "Epoch 88/100\n",
      "2696/2696 [==============================] - 155s 57ms/step - loss: 0.0591 - acc: 0.9670 - val_loss: 2.9067 - val_acc: 0.4221\n",
      "Epoch 89/100\n",
      "2696/2696 [==============================] - 157s 58ms/step - loss: 0.0616 - acc: 0.9662 - val_loss: 2.6802 - val_acc: 0.4377\n",
      "Epoch 90/100\n",
      "2696/2696 [==============================] - 154s 57ms/step - loss: 0.0599 - acc: 0.9692 - val_loss: 2.9168 - val_acc: 0.4288\n",
      "Epoch 91/100\n",
      "2696/2696 [==============================] - 155s 57ms/step - loss: 0.0658 - acc: 0.9629 - val_loss: 3.0741 - val_acc: 0.4073\n",
      "Epoch 92/100\n",
      "2696/2696 [==============================] - 157s 58ms/step - loss: 0.0628 - acc: 0.9674 - val_loss: 3.1337 - val_acc: 0.4206\n",
      "Epoch 93/100\n",
      "2696/2696 [==============================] - 154s 57ms/step - loss: 0.0629 - acc: 0.9644 - val_loss: 3.1995 - val_acc: 0.3917\n",
      "Epoch 94/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0631 - acc: 0.9655 - val_loss: 2.9012 - val_acc: 0.4236\n",
      "Epoch 95/100\n",
      "2696/2696 [==============================] - 148s 55ms/step - loss: 0.0579 - acc: 0.9666 - val_loss: 2.8748 - val_acc: 0.4184\n",
      "Epoch 96/100\n",
      "2696/2696 [==============================] - 144s 53ms/step - loss: 0.0561 - acc: 0.9674 - val_loss: 3.1951 - val_acc: 0.4117\n",
      "Epoch 97/100\n",
      "2696/2696 [==============================] - 147s 54ms/step - loss: 0.0570 - acc: 0.9670 - val_loss: 2.8733 - val_acc: 0.4332\n",
      "Epoch 98/100\n",
      "2696/2696 [==============================] - 146s 54ms/step - loss: 0.0553 - acc: 0.9662 - val_loss: 3.0108 - val_acc: 0.4199\n",
      "Epoch 99/100\n",
      "2696/2696 [==============================] - 144s 54ms/step - loss: 0.0567 - acc: 0.9662 - val_loss: 2.7816 - val_acc: 0.4325\n",
      "Epoch 100/100\n",
      "2696/2696 [==============================] - 147s 55ms/step - loss: 0.0580 - acc: 0.9674 - val_loss: 3.0203 - val_acc: 0.4221\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: /Users/huizhentang/Documents/Repos/Pet-projects/Ethnicity-Classifier/\n"
     ]
    }
   ],
   "source": [
    "#Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with io.open('model.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#Serialize weights to HDF5\n",
    "model.save_weights(save_path + \"model.h5\")\n",
    "\n",
    "print(\"Model saved to: \" + save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run evaluation on the trained model with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.72974288596\n",
      "Test accuracy: 0.436525612472\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
